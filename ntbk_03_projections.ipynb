{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583c06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d6dc0",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91fb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import PurePosixPath, Path\n",
    "\n",
    "from config.init import create_baseconfig_from_checkpoint\n",
    "from model.lgffem import LGFFEM\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import umap\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60fc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf98ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # to avoid crashing for truncated (corrupted images)\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    # open path as file to avoid ResourceWarning \n",
    "    # (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403d4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_embs_from_checkpoint_kimia(l_checkpoint: list[str]):\n",
    "    umap_proj_embs = []\n",
    "    \n",
    "    for path_checkpoint in l_checkpoint:\n",
    "        \n",
    "        # Create model from checkpoint\n",
    "        print(path_checkpoint)\n",
    "        path_checkpoint = os.path.join(path_checkpoint)\n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "        \n",
    "        base_config = create_baseconfig_from_checkpoint(checkpoint)\n",
    "\n",
    "        embedder = LGFFEM(base_config).eval().to(device)\n",
    "        match_n = embedder.neck.load_state_dict(checkpoint['model_neck_state_dict'], strict = False)\n",
    "        print('[++] Loaded neck weights.', match_n)\n",
    "        match_h = embedder.head.load_state_dict(checkpoint['model_head_state_dict'], strict = False)\n",
    "        print('[++] Loaded head weights.', match_h)\n",
    "        \n",
    "        img_transforms = v2.Compose([\n",
    "                            v2.ToImage(),\n",
    "                            v2.Resize(size=(224, 224)),\n",
    "                            v2.ToDtype(torch.float32, scale=True),\n",
    "                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                          ])\n",
    "        \n",
    "        # Get embeddings from Kimia Test imgs\n",
    "        PATH_TEST = '/thesis/classical/test-patches-kimia/'\n",
    "\n",
    "        dict_img = {}\n",
    "        for i in range(0,24):\n",
    "            path_i = f'/thesis/classical/test-patches-kimia/s{i}'\n",
    "            dict_img[f's{i}'] = natsorted([path for path in Path(path_i).rglob('*.jpg')], key=str)\n",
    "\n",
    "        img_l = list(itertools.chain.from_iterable(dict_img.values()))\n",
    "\n",
    "        KIMIA_CLASSES_IDX = dict([(f's{i}',i) for i in range(24)])\n",
    "        classes = [KIMIA_CLASSES_IDX[path.name.split('_')[0]] for path in img_l]\n",
    "        \n",
    "        im_embs_l = []\n",
    "        for i in tqdm(img_l):\n",
    "            im = pil_loader(i)\n",
    "            im = img_transforms(im).unsqueeze(0).to(device)\n",
    "            im_embs_l.append(embedder(im).detach().cpu().numpy())\n",
    "\n",
    "        X = np.stack(im_embs_l, axis=0).squeeze(1)\n",
    "        \n",
    "        # Projection 2D of the embbedings\n",
    "        reducer = umap.UMAP(random_state=42)\n",
    "        reducer.fit(X)\n",
    "\n",
    "        proj_embedding = reducer.transform(X)\n",
    "\n",
    "        # Verify that the result of calling transform is\n",
    "        # idenitical to accessing the embedding_ attribute\n",
    "        assert(np.all(proj_embedding == reducer.embedding_))\n",
    "        \n",
    "        umap_proj_embs.append((proj_embedding,classes))\n",
    "        \n",
    "    return umap_proj_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5b048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ff23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_embs_from_checkpoint_revised(l_checkpoint: list[str], test_dataset = 'roxford5k'):\n",
    "    umap_proj_embs = []\n",
    "    \n",
    "    data_root = Path('/thesis/classical/revisitop/datasets')\n",
    "    img_root = Path(data_root, f'{test_dataset}/jpg/')\n",
    "    gnd_fname = Path(data_root, f'{test_dataset}/gnd_{test_dataset}.pkl')\n",
    "    \n",
    "    with open(gnd_fname, 'rb') as f:\n",
    "        cfg = pickle.load(f)\n",
    "\n",
    "    for path_checkpoint in l_checkpoint:\n",
    "        \n",
    "        # Create model from checkpoint\n",
    "        print(path_checkpoint)\n",
    "        path_checkpoint = os.path.join(path_checkpoint)\n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "        \n",
    "        base_config = create_baseconfig_from_checkpoint(checkpoint)\n",
    "\n",
    "        embedder = LGFFEM(base_config).eval().to(device)\n",
    "        match_n = embedder.neck.load_state_dict(checkpoint['model_neck_state_dict'], strict = False)\n",
    "        print('[++] Loaded neck weights.', match_n)\n",
    "        match_h = embedder.head.load_state_dict(checkpoint['model_head_state_dict'], strict = False)\n",
    "        print('[++] Loaded head weights.', match_h)\n",
    "        \n",
    "        img_transforms = v2.Compose([\n",
    "                            v2.ToImage(),\n",
    "                            v2.Resize(size=(224, 224)),\n",
    "                            v2.ToDtype(torch.float32, scale=True),\n",
    "                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                          ])\n",
    "\n",
    "        # Extraction features dataset\n",
    "        #img_l = list(data_root.glob('*.jpg'))\n",
    "        img_l = [Path(img_root, f'{fn}.jpg') for fn in cfg['imlist']]\n",
    "        landmarks_classes = ['_'.join(p_i.stem.split('_')[:-1]) for p_i in img_l]\n",
    "        \n",
    "        im_embs_l = []\n",
    "        for i in tqdm(img_l):\n",
    "            im = pil_loader(i)\n",
    "            im = img_transforms(im).unsqueeze(0).to(device)\n",
    "            im_embs_l.append(embedder(im).detach().cpu().numpy())\n",
    "        \n",
    "        X = np.stack(im_embs_l, axis=0).squeeze(1)\n",
    "        \n",
    "        # Projection 2D of the embbedings\n",
    "        reducer = umap.UMAP(random_state=42)\n",
    "        reducer.fit(X)\n",
    "\n",
    "        proj_embedding = reducer.transform(X)\n",
    "\n",
    "        # Verify that the result of calling transform is\n",
    "        # idenitical to accessing the embedding_ attribute\n",
    "        assert(np.all(proj_embedding == reducer.embedding_))\n",
    "        \n",
    "        umap_proj_embs.append((proj_embedding, landmarks_classes))\n",
    "\n",
    "    return umap_proj_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d0b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5bbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_embs_from_checkpoint_pannuke(l_checkpoint: list[str]):\n",
    "    umap_proj_embs = []\n",
    "    \n",
    "    data_root = Path('/thesis/classical/pannuke/images/')\n",
    "\n",
    "    for path_checkpoint in l_checkpoint:\n",
    "        \n",
    "        # Create model from checkpoint\n",
    "        print(path_checkpoint)\n",
    "        path_checkpoint = os.path.join(path_checkpoint)\n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "        \n",
    "        base_config = create_baseconfig_from_checkpoint(checkpoint)\n",
    "\n",
    "        embedder = LGFFEM(base_config).eval().to(device)\n",
    "        match_n = embedder.neck.load_state_dict(checkpoint['model_neck_state_dict'], strict = False)\n",
    "        print('[++] Loaded neck weights.', match_n)\n",
    "        match_h = embedder.head.load_state_dict(checkpoint['model_head_state_dict'], strict = False)\n",
    "        print('[++] Loaded head weights.', match_h)\n",
    "        \n",
    "        img_transforms = v2.Compose([\n",
    "                            v2.ToImage(),\n",
    "                            v2.Resize(size=(224, 224)),\n",
    "                            v2.ToDtype(torch.float32, scale=True),\n",
    "                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                          ])\n",
    "\n",
    "        # Extraction features dataset\n",
    "        img_l = list(data_root.glob('*.png'))\n",
    "        tissue_classes = [fn.stem.split('_')[-1] for fn in img_l]\n",
    "        \n",
    "        im_embs_l = []\n",
    "        for i in tqdm(img_l):\n",
    "            im = pil_loader(i)\n",
    "            im = img_transforms(im).unsqueeze(0).to(device)\n",
    "            im_embs_l.append(embedder(im).detach().cpu().numpy())\n",
    "        \n",
    "        X = np.stack(im_embs_l, axis=0).squeeze(1)\n",
    "        \n",
    "        # Projection 2D of the embbedings\n",
    "        reducer = umap.UMAP(random_state=42)\n",
    "        reducer.fit(X)\n",
    "\n",
    "        proj_embedding = reducer.transform(X)\n",
    "\n",
    "        # Verify that the result of calling transform is\n",
    "        # idenitical to accessing the embedding_ attribute\n",
    "        assert(np.all(proj_embedding == reducer.embedding_))\n",
    "        \n",
    "        umap_proj_embs.append((proj_embedding, tissue_classes))\n",
    "\n",
    "    return umap_proj_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42f023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4e1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = ['/thesis/checkpoint/BASE/A_BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth',\n",
    "                 '/thesis/checkpoint/BASE/B1_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch200.pth',\n",
    "                 '/thesis/checkpoint/BASE/B2_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth',\n",
    "                 '/thesis/checkpoint/BASE/B3_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch199.pth',\n",
    "                 '/thesis/checkpoint/BASE/C_BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8345540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/A_BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:39<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B1_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch200.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:38<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B2_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:38<00:00, 34.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B3_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch199.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:38<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/C_BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:38<00:00, 34.33it/s]\n"
     ]
    }
   ],
   "source": [
    "list_projs_kimia = umap_embs_from_checkpoint_kimia(final_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c65329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/A_BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [02:26<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B1_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch200.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [02:34<00:00, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B2_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [02:32<00:00, 32.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B3_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch199.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [02:35<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/C_BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [02:37<00:00, 31.62it/s]\n"
     ]
    }
   ],
   "source": [
    "list_projs_roxford5k = umap_embs_from_checkpoint_revised(final_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4debe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/A_BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6322/6322 [03:18<00:00, 31.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B1_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch200.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6322/6322 [03:15<00:00, 32.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B2_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6322/6322 [03:11<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B3_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch199.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6322/6322 [03:13<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/C_BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6322/6322 [03:14<00:00, 32.50it/s]\n"
     ]
    }
   ],
   "source": [
    "list_projs_rparis6k = umap_embs_from_checkpoint_revised(final_models, test_dataset='rparis6k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02155528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/A_BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7901/7901 [03:20<00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B1_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch200.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7901/7901 [03:18<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B2_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7901/7901 [03:26<00:00, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/B3_BASE-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch199.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7901/7901 [03:20<00:00, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/C_BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7901/7901 [03:21<00:00, 39.28it/s]\n"
     ]
    }
   ],
   "source": [
    "list_projs_pannuke = umap_embs_from_checkpoint_pannuke(final_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281b789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22472107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (emb_proj,emb_c),path_checkpoint in zip(list_projs_kimia, final_models):\n",
    "    \n",
    "    fn_fig = Path(path_checkpoint).stem\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    sca = ax.scatter(emb_proj[:, 0], emb_proj[:, 1], c=emb_c, cmap='nipy_spectral', s=11)\n",
    "\n",
    "    cbar = fig.colorbar(sca, boundaries=np.arange(25)-0.5, pad=.02, fraction=.12, aspect=20, shrink=0.9)    \n",
    "    cbar.set_ticks(np.arange(24))\n",
    "    cbar.set_label('ID of classes',size=18)\n",
    "    cbar.ax.tick_params(labelsize=13)    \n",
    "\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "\n",
    "    fig.savefig(f'figures/emb/kimia_{fn_fig}.eps', format='eps', dpi=1200)\n",
    "#     plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dec6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (emb_proj,emb_c), path_checkpoint in zip(list_projs_roxford5k, final_models):\n",
    "    \n",
    "    id_classes = {x:i for i,x in enumerate(set(emb_c))}\n",
    "    classes = list(id_classes.keys())\n",
    "    \n",
    "    fn_fig = Path(path_checkpoint).stem\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    sca = ax.scatter(emb_proj[:, 0], emb_proj[:, 1], c=[id_classes[id_i] for id_i in emb_c],\n",
    "                     cmap='nipy_spectral', s=11)\n",
    "\n",
    "    cbar = fig.colorbar(sca, boundaries=np.arange(len(classes)+1)-0.5, pad=.02, fraction=.12, aspect=20, shrink=0.9)    \n",
    "    cbar.set_ticks(np.arange(len(classes)))\n",
    "    cbar.set_label('Landmarks',size=18)\n",
    "    cbar.ax.tick_params(labelsize=13)    \n",
    "    cbar.ax.set_yticklabels(classes)\n",
    "\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "\n",
    "    fig.savefig(f'figures/emb/roxford5k_{fn_fig}.eps', format='eps', dpi=1200)\n",
    "#     plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1ac1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (emb_proj,emb_c), path_checkpoint in zip(list_projs_rparis6k, final_models):\n",
    "    \n",
    "    id_classes = {x:i for i,x in enumerate(set(emb_c))}\n",
    "    classes = list(id_classes.keys())\n",
    "    \n",
    "    fn_fig = Path(path_checkpoint).stem\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    sca = ax.scatter(emb_proj[:, 0], emb_proj[:, 1], c=[id_classes[id_i] for id_i in emb_c],\n",
    "                     cmap='nipy_spectral', s=11)\n",
    "\n",
    "    cbar = fig.colorbar(sca, boundaries=np.arange(len(classes)+1)-0.5, pad=.02, fraction=.12, aspect=20, shrink=0.9)    \n",
    "    cbar.set_ticks(np.arange(len(classes)))\n",
    "    cbar.set_label('Landmarks',size=18)\n",
    "    cbar.ax.tick_params(labelsize=13)    \n",
    "    cbar.ax.set_yticklabels(classes)\n",
    "\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "\n",
    "    fig.savefig(f'figures/emb/rparis6k_{fn_fig}.eps', format='eps', dpi=1200)\n",
    "#     plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59daa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (emb_proj,emb_c), path_checkpoint in zip(list_projs_pannuke, final_models):\n",
    "    \n",
    "    id_classes = {x:i for i,x in enumerate(set(emb_c))}\n",
    "    classes = list(id_classes.keys())\n",
    "    \n",
    "    fn_fig = Path(path_checkpoint).stem\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    sca = ax.scatter(emb_proj[:, 0], emb_proj[:, 1], c=[id_classes[id_i] for id_i in emb_c],\n",
    "                     cmap='nipy_spectral', s=11)\n",
    "\n",
    "    cbar = fig.colorbar(sca, boundaries=np.arange(len(classes)+1)-0.5, pad=.02, fraction=.12, aspect=20, shrink=0.9)    \n",
    "    cbar.set_ticks(np.arange(len(classes)))\n",
    "    cbar.set_label('Landmarks',size=18)\n",
    "    cbar.ax.tick_params(labelsize=13)    \n",
    "    cbar.ax.set_yticklabels(classes)\n",
    "\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "\n",
    "    fig.savefig(f'figures/emb/pannuke_{fn_fig}.eps', format='eps', dpi=1200)\n",
    "#     plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c272980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
