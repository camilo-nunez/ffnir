{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48db7d",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec481d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from config.init import create_baseconfig_from_checkpoint\n",
    "from model.lgffem import LGFFEM\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49633023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f2772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # to avoid crashing for truncated (corrupted images)\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    # open path as file to avoid ResourceWarning \n",
    "    # (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25ae00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_embs_from_checkpoint(l_checkpoint: list[str]):\n",
    "    umap_proj_embs = []\n",
    "    \n",
    "    for path_checkpoint in l_checkpoint:\n",
    "        \n",
    "        # Create model from checkpoint\n",
    "        print(path_checkpoint)\n",
    "        path_checkpoint = os.path.join(path_checkpoint)\n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "        \n",
    "        base_config = create_baseconfig_from_checkpoint(checkpoint)\n",
    "\n",
    "        embedder = LGFFEM(base_config).eval().to(device)\n",
    "        match_n = embedder.neck.load_state_dict(checkpoint['model_neck_state_dict'], strict = False)\n",
    "        print('[++] Loaded neck weights.', match_n)\n",
    "        match_h = embedder.head.load_state_dict(checkpoint['model_head_state_dict'], strict = False)\n",
    "        print('[++] Loaded head weights.', match_h)\n",
    "        \n",
    "        img_transforms = v2.Compose([\n",
    "                            v2.ToImage(),\n",
    "                            v2.Resize(size=(224, 224)),\n",
    "                            v2.ToDtype(torch.float32, scale=True),\n",
    "                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                          ])\n",
    "        \n",
    "        # Get embeddings from Kimia Test imgs\n",
    "        PATH_TEST = '/thesis/classical/test-patches-kimia/'\n",
    "\n",
    "        dict_img = {}\n",
    "        for i in range(0,24):\n",
    "            path_i = f'/thesis/classical/test-patches-kimia/s{i}'\n",
    "            dict_img[f's{i}'] = natsorted([path for path in Path(path_i).rglob('*.jpg')], key=str)\n",
    "\n",
    "        img_l = list(itertools.chain.from_iterable(dict_img.values()))\n",
    "\n",
    "        KIMIA_CLASSES_IDX = dict([(f's{i}',i) for i in range(24)])\n",
    "        classes = [KIMIA_CLASSES_IDX[path.name.split('_')[0]] for path in img_l]\n",
    "        \n",
    "        im_embs_l = []\n",
    "        for i in tqdm(img_l):\n",
    "            im = pil_loader(i)\n",
    "            im = img_transforms(im).unsqueeze(0).to(device)\n",
    "            im_embs_l.append(embedder(im).detach().cpu().numpy())\n",
    "\n",
    "        X = np.stack(im_embs_l, axis=0).squeeze(1)\n",
    "        \n",
    "        # Projection 2D of the embbedings\n",
    "        reducer = umap.UMAP(random_state=42)\n",
    "        reducer.fit(X)\n",
    "\n",
    "        proj_embedding = reducer.transform(X)\n",
    "\n",
    "        # Verify that the result of calling transform is\n",
    "        # idenitical to accessing the embedding_ attribute\n",
    "        assert(np.all(proj_embedding == reducer.embedding_))\n",
    "        \n",
    "        umap_proj_embs.append((proj_embedding,classes))\n",
    "        \n",
    "    return umap_proj_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cdb2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = ['/thesis/checkpoint/BASE/BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth',\n",
    "                '/thesis/checkpoint/BASE/BASE-B-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth',\n",
    "                '/thesis/checkpoint/BASE/BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1415ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/BASE-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch10--in1k-224.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:39<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/BASE-B-EMB-PAN-11_convnextv2-02_neck_512_3-00_head_A-epoch198.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:41<00:00, 31.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/thesis/checkpoint/BASE/BASE-EMB-KIMIA-11_convnextv2-02_neck_512_3-00_head_A-epoch499.pth\n",
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:42<00:00, 30.90it/s]\n"
     ]
    }
   ],
   "source": [
    "list_projs = umap_embs_from_checkpoint(final_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed1c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (emb_proj,emb_c),path_checkpoint in zip(list_projs, final_models):\n",
    "    \n",
    "    fn_fig = Path(path_checkpoint).stem\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    sca = ax.scatter(emb_proj[:, 0], emb_proj[:, 1], c=emb_c, cmap='nipy_spectral', s=10)\n",
    "    fig.colorbar(sca, ax=ax, boundaries=np.arange(25)-0.5, label='ID of classes').set_ticks(np.arange(24))\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    fig.savefig(f'figures/{fn_fig}.eps', format='eps', dpi=1200)\n",
    "#     plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447763a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
