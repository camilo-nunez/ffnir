{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec559df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070548dd",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73066e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from config.init import create_baseconfig_from_checkpoint\n",
    "from model.lgffem import LGFFEM\n",
    "\n",
    "from utils.revisitop.dataset import configdataset\n",
    "from utils.revisitop.evaluate import compute_map\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7d9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bf8f6",
   "metadata": {},
   "source": [
    "## Create model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a4994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = os.path.join('/thesis/checkpoint/20240212_2301-EMB-11_convnextv2-02_neck_512_3-00_head_A-epoch4.pth')\n",
    "checkpoint = torch.load(path_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a16aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[++] Loaded neck weights. <All keys matched successfully>\n",
      "[++] Loaded head weights. <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "base_config = create_baseconfig_from_checkpoint(checkpoint)\n",
    "\n",
    "embedder = LGFFEM(base_config).eval().to(device)\n",
    "match_n = embedder.neck.load_state_dict(checkpoint['model_neck_state_dict'], strict = False)\n",
    "print('[++] Loaded neck weights.', match_n)\n",
    "match_h = embedder.head.load_state_dict(checkpoint['model_head_state_dict'], strict = False)\n",
    "print('[++] Loaded head weights.', match_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fa740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = v2.Compose([\n",
    "                            v2.ToImage(),\n",
    "                            v2.Resize(size=(224, 224)),\n",
    "                            v2.ToDtype(torch.float32, scale=True),\n",
    "                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838174b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea69069",
   "metadata": {},
   "source": [
    "## Get embeddings from Kimia Test imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c409a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import itertools\n",
    "\n",
    "PATH_TEST = '/thesis/classical/test-patches-kimia/'\n",
    "\n",
    "# img_l = [path for path in Path(PATH_TEST).rglob('*.jpg')]\n",
    "# label_l = [path.name for path in img_l]\n",
    "\n",
    "dict_img = {}\n",
    "for i in range(0,24):\n",
    "    path_i = f'/thesis/classical/test-patches-kimia/s{i}'\n",
    "    dict_img[f's{i}'] = natsorted([path for path in Path(path_i).rglob('*.jpg')], key=str)\n",
    "    \n",
    "img_l = list(itertools.chain.from_iterable(dict_img.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204bf229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # to avoid crashing for truncated (corrupted images)\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    # open path as file to avoid ResourceWarning \n",
    "    # (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a95ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1325/1325 [00:38<00:00, 34.00it/s]\n"
     ]
    }
   ],
   "source": [
    "im_embs_l = []\n",
    "for i in tqdm(img_l):\n",
    "    im = pil_loader(i)\n",
    "    im = img_transforms(im).unsqueeze(0).to(device)\n",
    "    im_embs_l.append(embedder(im).detach().cpu().numpy())\n",
    "\n",
    "X = np.stack(im_embs_l, axis=0).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffee41c",
   "metadata": {},
   "source": [
    "## Create index and retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1142ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cafa5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "size, dim = X.shape\n",
    "m_neighbors = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b501a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantizer = faiss.IndexFlatIP(dim)\n",
    "# index = faiss.IndexIVFPQ(quantizer, dim, 316, 128, 8)\n",
    "\n",
    "# index = faiss.IndexHNSWFlat(dim, m_neighbors)\n",
    "index = faiss.IndexFlatL2(dim) ##euclidean\n",
    "# index = faiss.IndexFlatIP(dim) ##cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36afafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(X)\n",
    "index.add(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc905779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims, ranks_f = index.search(X, size)\n",
    "# ranks_f = np.swapaxes(ranks_f,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0cfd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.7753 71.0189 72.9036\n"
     ]
    }
   ],
   "source": [
    "eta_p = 0\n",
    "eta_w = 0\n",
    "\n",
    "i_low = 0\n",
    "for s in range(0,24):\n",
    "    v = dict_img[f's{s}']\n",
    "    \n",
    "    i_hight = i_low + len(v)\n",
    "    \n",
    "    labels = set([path.name for path in img_l[i_low:i_hight]])\n",
    "    retrieve = set([path.name for path in [img_l[idx] for idx in ranks_f[i_low,:i_hight]]]) ## k=1\n",
    "    \n",
    "    cardi = len(retrieve&labels)\n",
    "    \n",
    "    eta_p+=cardi\n",
    "    eta_w+=(cardi/len(v))\n",
    "\n",
    "    \n",
    "    i_low = i_hight\n",
    "    \n",
    "eta_p = eta_p/len(img_l)\n",
    "eta_w = eta_w/24\n",
    "eta_tot = eta_p*eta_w\n",
    "\n",
    "print(round(eta_tot*100,4),round(eta_p*100,4),round(eta_w*100,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f372f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
